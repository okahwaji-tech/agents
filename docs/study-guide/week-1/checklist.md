# Week 1 Progress Checklist

Track your progress through Week 1's learning materials. Check off each item as you complete it.

## üìê Mathematical Foundations

### Core Topics
- [ ] **Probability Theory** (3-4 hours)
 - [ ] Read [Probability Theory Materials](../../materials/math/probability-theory.md)
 - [ ] Complete practice problems
 - [ ] Understand conditional probability and Bayes' theorem

- [ ] **Information Theory** (2-3 hours)
 - [ ] Read [Information Theory Materials](../../materials/math/information-theory.md)
 - [ ] Calculate entropy for simple text sequences
 - [ ] Understand cross-entropy loss function

- [ ] **Linear Algebra** (3-4 hours)
 - [ ] Review [Linear Algebra Materials](../../materials/math/linear-algebra.md)
 - [ ] Practice matrix operations
 - [ ] Understand vector spaces and transformations

### Advanced Topics
- [ ] **Matrix Operations** (1-2 hours)
 - [ ] Review [Matrix Multiplication](../../materials/math/matrix-multiplication.md)
 - [ ] Practice efficient computation

- [ ] **Eigenvalues & Eigenvectors** (3 hours)
 - [ ] Study [Eigenvalues & Eigenvectors](../../materials/math/eigenvalues-eigenvectors.md)
 - [ ] Understand geometric interpretation

## ü§ñ Machine Learning & RL

- [ ] **Markov Decision Processes** (3 hours)
 - [ ] Read [MDP Materials](../../materials/ml/mdp.md)
 - [ ] Understand states, actions, and rewards

- [ ] **Reinforcement Learning Basics** (4 hours)
 - [ ] Study [RL Materials](../../materials/ml/reinforcement-learning.md)
 - [ ] Connect RL concepts to language modeling

- [ ] **RL-LLM Connections** (3 hours)
 - [ ] Read [RL-LLM Foundation](../../materials/ml/rl-llm-foundation.md)
 - [ ] Understand language modeling as sequential decision-making

## üß† LLM Fundamentals

- [ ] **Introduction to LLMs** (2-3 hours)
 - [ ] Read [LLM Fundamentals](../../materials/llm/llm-fundamentals.md)
 - [ ] Understand transformer architecture basics

- [ ] **Word Embeddings** (2-3 hours)
 - [ ] Study [Word Embeddings](../../materials/llm/word-embeddings.md)
 - [ ] Implement basic embedding examples

- [ ] **Evaluation Methods** (2 hours)
 - [ ] Review [Evaluation Methods](../../materials/llm/evaluation.md)
 - [ ] Understand perplexity and other metrics

## üìö Key Readings

- [ ] **"Attention Is All You Need"** - [ArXiv](https://arxiv.org/abs/1706.03762)
- [ ] **Stanford CS224n Lecture 1** - NLP with Deep Learning
- [ ] **Stanford CS234 Lecture 1** - Introduction to RL

## üíª Hands-On Practice

- [ ] **First LLM Program**
 - [ ] Set up development environment
 - [ ] Run basic text generation example
 - [ ] Experiment with different prompts

- [ ] **Code Examples**
 - [ ] Review gradient descent implementation
 - [ ] Study SVD examples in PyTorch

## üè• Healthcare Applications

- [ ] **Medical AI Safety** considerations
- [ ] **Clinical NLP** applications overview
- [ ] **Healthcare Bias** and fairness principles

## üéØ Week 1 Goals

By the end of Week 1, you should be able to:

1. ‚úÖ Explain how LLMs use probability to generate text
2. ‚úÖ Calculate entropy and understand its role in language modeling
3. ‚úÖ Describe the connection between RL and language modeling
4. ‚úÖ Implement a basic text generation program
5. ‚úÖ Identify key considerations for healthcare AI applications

## üìù Notes Section

Use this space to track questions, insights, or areas needing review:

```
[Your notes here]
```

---

**Estimated Total Time**: 35-40 hours

!!! tip "Study Tip"
 Focus on understanding concepts rather than memorizing formulas. The mathematical foundations will become clearer as you see them applied in LLM contexts.
